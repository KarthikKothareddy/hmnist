{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>9958.000000</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7470</td>\n",
       "      <td>10015</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>HAM_0000835</td>\n",
       "      <td>ISIC_0032462</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6705</td>\n",
       "      <td>5340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5406</td>\n",
       "      <td>2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.863828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.968614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lesion_id      image_id     dx dx_type          age    sex  \\\n",
       "count         10015         10015  10015   10015  9958.000000  10015   \n",
       "unique         7470         10015      7       4          NaN      3   \n",
       "top     HAM_0000835  ISIC_0032462     nv   histo          NaN   male   \n",
       "freq              6             1   6705    5340          NaN   5406   \n",
       "mean            NaN           NaN    NaN     NaN    51.863828    NaN   \n",
       "std             NaN           NaN    NaN     NaN    16.968614    NaN   \n",
       "min             NaN           NaN    NaN     NaN     0.000000    NaN   \n",
       "25%             NaN           NaN    NaN     NaN    40.000000    NaN   \n",
       "50%             NaN           NaN    NaN     NaN    50.000000    NaN   \n",
       "75%             NaN           NaN    NaN     NaN    65.000000    NaN   \n",
       "max             NaN           NaN    NaN     NaN    85.000000    NaN   \n",
       "\n",
       "       localization  \n",
       "count         10015  \n",
       "unique           15  \n",
       "top            back  \n",
       "freq           2192  \n",
       "mean            NaN  \n",
       "std             NaN  \n",
       "min             NaN  \n",
       "25%             NaN  \n",
       "50%             NaN  \n",
       "75%             NaN  \n",
       "max             NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"../HAM10000_metadata.csv\")\n",
    "metadata.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
     ]
    }
   ],
   "source": [
    "print(metadata.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n"
     ]
    }
   ],
   "source": [
    "labels = list(metadata.dx.unique())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: dx, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffaac08c3c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 5))\n",
    "counts = metadata[\"dx\"].value_counts()\n",
    "print(counts)\n",
    "counts.plot(kind='bar', ax=ax1)\n",
    "#metadata[\"dx\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2000\n",
    "\n",
    "# parse out all classes to individual dataframes\n",
    "nv = metadata[metadata[\"dx\"] == \"nv\"]\n",
    "nv = nv.sample(n=threshold)\n",
    "nv.name = \"nv\"\n",
    "mel = metadata[metadata[\"dx\"] == \"mel\"]\n",
    "mel.name = \"mel\"\n",
    "bkl = metadata[metadata[\"dx\"] == \"bkl\"]\n",
    "bkl.name = \"bkl\"\n",
    "bcc = metadata[metadata[\"dx\"] == \"bcc\"]\n",
    "bcc.name = \"bcc\"\n",
    "akiec = metadata[metadata[\"dx\"] == \"akiec\"]\n",
    "akiec.name = \"akiec\"\n",
    "vasc = metadata[metadata[\"dx\"] == \"vasc\"]\n",
    "vasc.name = \"vasc\"\n",
    "df = metadata[metadata[\"dx\"] == \"df\"]\n",
    "df.name = \"df\"\n",
    "# list out\n",
    "classes = [nv, mel, bkl, bcc, akiec, vasc, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess accordingly\n",
    "def preprocess(_image):\n",
    "    #_image = cv2.cvtColor(_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #_image = cv2.equalizeHist(_image) \n",
    "    #_image = cv2.GaussianBlur(_image, (3,3), 1)\n",
    "    _image = cv2.cvtColor(_image, cv2.COLOR_RGB2HSV)\n",
    "    H,S,V = cv2.split(_image)\n",
    "    _V = cv2.equalizeHist(V) \n",
    "    _image = cv2.merge([H, S, _V])\n",
    "    _image = cv2.cvtColor(_image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return _image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate into Respective Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 1600, Test: 400 images found for class nv\n",
      "Moving complete for class nv...\n",
      "Training: 890, Test: 223 images found for class mel\n",
      "Moving complete for class mel...\n",
      "Training: 879, Test: 220 images found for class bkl\n",
      "Moving complete for class bkl...\n",
      "Training: 411, Test: 103 images found for class bcc\n",
      "Moving complete for class bcc...\n",
      "Training: 261, Test: 66 images found for class akiec\n",
      "Moving complete for class akiec...\n",
      "Training: 113, Test: 29 images found for class vasc\n",
      "Moving complete for class vasc...\n",
      "Training: 92, Test: 23 images found for class df\n",
      "Moving complete for class df...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#threshold = 2000\n",
    "# seperate images to each directory \n",
    "os.mkdir(\"ham_labled\")\n",
    "os.mkdir(\"ham_labled/train\")\n",
    "os.mkdir(\"ham_labled/test\")\n",
    "\n",
    "# each class\n",
    "for _class in classes:\n",
    "    _train, _test = train_test_split(_class, test_size = 0.2)\n",
    "    print(\"Training: {}, Test: {} images found for class {}\".format(len(_train), len(_test), _class.name))\n",
    "    # train \n",
    "    os.mkdir(\"ham_labled/train/{}\".format(_class.name))\n",
    "    for i, row in _train.iterrows():\n",
    "        image_id = row[\"image_id\"]\n",
    "        img = cv2.imread(\"../ham10000/{}.jpg\".format(image_id))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        cv2.imwrite(\"../ham10000/{}.jpg\".format(image_id), img)\n",
    "        shutil.move(\n",
    "            src=\"../ham10000/{}.jpg\".format(image_id), \n",
    "            dst=\"ham_labled/train/{}/\".format(_class.name)\n",
    "        )\n",
    "    # test\n",
    "    os.mkdir(\"ham_labled/test/{}\".format(_class.name))\n",
    "    for i, row in _test.iterrows():\n",
    "        image_id = row[\"image_id\"]\n",
    "        img = cv2.imread(\"../ham10000/{}.jpg\".format(image_id))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        cv2.imwrite(\"../ham10000/{}.jpg\".format(image_id), img)\n",
    "        shutil.move(\n",
    "            src=\"../ham10000/{}.jpg\".format(image_id), \n",
    "            dst=\"ham_labled/test/{}/\".format(_class.name)\n",
    "        )\n",
    "    print(\"Moving complete for class {}...\".format(_class.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augumentation\n",
    "\n",
    "Before we can start passing above images through a CNN feature extractor, we will augument images to address class imbalance problem and set a threshold of 5000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "_generator = ImageDataGenerator(\n",
    "    width_shift_range=0.001,\n",
    "    height_shift_range=0.001,\n",
    "    zoom_range=0.01,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "def load_images(directory):\n",
    "    images = [cv2.cvtColor(cv2.imread(os.path.join(directory, file)), cv2.COLOR_BGR2RGB)\n",
    "              for file in os.listdir(directory)]\n",
    "    images = [img_to_array(image, data_format=\"channels_last\") for image in images]\n",
    "    images = np.array(images)\n",
    "    images = images.astype(\"float\")\n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augumenting images for class mel...\n",
      "Augumenting images for class bkl...\n",
      "Augumenting images for class bcc...\n",
      "Augumenting images for class akiec...\n",
      "Augumenting images for class vasc...\n",
      "Augumenting images for class df...\n"
     ]
    }
   ],
   "source": [
    "batch = 32\n",
    "for _class in classes:\n",
    "    _name = _class.name\n",
    "    if len(_class) >= threshold:\n",
    "        continue\n",
    "    else:\n",
    "        # what a pain ....PHEW!\n",
    "        if os.path.exists(\"ham_labled/train/{}/.ipynb_checkpoints/\".format(_name)):\n",
    "            shutil.rmtree(\"ham_labled/train/{}/.ipynb_checkpoints/\".format(_name))\n",
    "        print(\"Augumenting images for class {}...\".format(_name))\n",
    "        X = load_images(\"ham_labled/train/{}/\".format(_name))\n",
    "        _auguments = _generator.flow(\n",
    "            x=X,\n",
    "            y=None,\n",
    "            batch_size=batch,\n",
    "            save_format=\"jpg\",\n",
    "            save_prefix=\"augumented\",\n",
    "            save_to_dir=\"ham_labled/train/{}/\".format(_name)\n",
    "        )\n",
    "        for _ in range(int(np.ceil((threshold - X.shape[0])/batch))):\n",
    "            x = next(_auguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the newly generated Images and process them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Running setup.py bdist_wheel for imutils ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\n",
      "Successfully built imutils\n",
      "\u001b[31mscikit-umfpack 0.3.2 has requirement numpy>=1.15.3, but you'll have numpy 1.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "13190 total images found...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imutils import paths\n",
    "except ModuleNotFoundError:\n",
    "    !pip install imutils\n",
    "    from imutils import paths\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "image_paths = list(paths.list_images(\"ham_labled/train\"))\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "labels = [cls.split(os.path.sep)[-2] for cls in image_paths]\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "print(\"{} total images found...\".format(len(image_paths)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential, Model\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(object):\n",
    "\n",
    "    def __init__(self, height, width, channels, classes, parameter_scaling):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.output_classes = classes\n",
    "        self.scale = parameter_scaling\n",
    "        \n",
    "    \"\"\"   \n",
    "    def model(self):\n",
    "        _model = ResNet50(\n",
    "            weights=\"imagenet\",\n",
    "            include_top=False,\n",
    "            input_shape=(self.height, self.width, self.channels)\n",
    "        )\n",
    "        x = _model.output\n",
    "        x = Dropout(0.75)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(512, activation=\"relu\")(x)\n",
    "        x = Dropout(0.75)(x)\n",
    "        x = Dense(self.output_classes, activation=\"softmax\")(x)\n",
    "        model = Model(inputs=_model.input, outputs=x)\n",
    "        return model\n",
    "        \n",
    "    \"\"\"  \n",
    "    def model(self):\n",
    "        \n",
    "        input_shape = (self.height, self.width, self.channels)\n",
    "        axis = -1\n",
    "        # if using theano\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            input_shape = (self.channels, self.height, self.width)\n",
    "            axis = 1\n",
    "        # initiate model\n",
    "        _model = Sequential()\n",
    "        \n",
    "        # conv_1\n",
    "        _model.add(Conv2D(\n",
    "            12, (3, 3),\n",
    "            padding=\"same\",\n",
    "            input_shape=input_shape)\n",
    "        )\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        _model.add(Flatten())\n",
    "        _model.add(Dropout(0.5))\n",
    "        # classifier\n",
    "        _model.add(Dense(self.output_classes))\n",
    "        _model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return model\n",
    "        return _model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "queue = manager.Queue(maxsize=10)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-4\n",
    "EPOCHS = 1\n",
    "PARAMETER_SCALING = 16\n",
    "IM_WIDTH = 224\n",
    "IM_HEIGHT = 224\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    adjusted_lr = 1e-5 if epoch >= 10 else lr\n",
    "    print(\"Current Learning Rate: {}, Adjusted Learning Rate: {}\".format(\n",
    "        str(lr), str(adjusted_lr)\n",
    "    ))\n",
    "    return adjusted_lr\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def train():\n",
    "    \n",
    "        h_callbacks = [\n",
    "            callbacks.TensorBoard(\n",
    "                log_dir=\"tensorboard\",\n",
    "                write_graph=True,\n",
    "                write_images=False\n",
    "            ),\n",
    "            LearningRateScheduler(lr_scheduler)\n",
    "        ]\n",
    "        _model = CustomNet(\n",
    "            height=IM_HEIGHT,\n",
    "            width=IM_WIDTH,\n",
    "            channels=3,\n",
    "            classes=7,\n",
    "            parameter_scaling=PARAMETER_SCALING\n",
    "        ).model()\n",
    "        _model.compile(\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            optimizer=Adam(lr=LR),\n",
    "            metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy]\n",
    "        )\n",
    "        \n",
    "        # generators made according to the post\n",
    "        # https://github.com/keras-team/keras/issues/5862\n",
    "        data_generator = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        train_generator = data_generator.flow_from_directory(\n",
    "            directory=\"ham_labled/train\",\n",
    "            target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "            shuffle=True,\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset=\"training\"\n",
    "        )\n",
    "        valid_generator = data_generator.flow_from_directory(\n",
    "            directory=\"ham_labled/train\",\n",
    "            target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "            shuffle=True,\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset=\"validation\"\n",
    "        )\n",
    "        # train\n",
    "        history = _model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=valid_generator.samples//valid_generator.batch_size,\n",
    "            callbacks=h_callbacks,\n",
    "            epochs=EPOCHS\n",
    "        )\n",
    "        return _model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10556 images belonging to 7 classes.\n",
      "Found 2634 images belonging to 7 classes.\n",
      "Epoch 1/1\n",
      "Current Learning Rate: 9.999999747378752e-05, Adjusted Learning Rate: 9.999999747378752e-05\n",
      " 23/164 [===>..........................] - ETA: 12:40 - loss: 3.4499 - categorical_accuracy: 0.3193 - top_2_accuracy: 0.5156 - top_3_accuracy: 0.6467"
     ]
    }
   ],
   "source": [
    "model_ret, history_ret = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICTION\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from imutils import paths\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1064 images belonging to 7 classes.\n",
      "{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n"
     ]
    }
   ],
   "source": [
    "# method-1\n",
    "def load_test_data(directory):\n",
    "    data = []\n",
    "    labels = []\n",
    "    image_paths = list(paths.list_images(directory))\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        # read\n",
    "        image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        # keras format\n",
    "        image = img_to_array(image, data_format=\"channels_last\")\n",
    "        label = image_path.split(os.path.sep)[-2]\n",
    "        # append\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "    # conversions\n",
    "    data = np.array(data)\n",
    "    data = data.astype(\"float\")\n",
    "    return data, np.array(labels)\n",
    "\n",
    "# easy generator method\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = data_generator.flow_from_directory(\n",
    "    directory=\"ham_labled/test/\",\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=1\n",
    ")\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064, 224, 224, 3)\n",
      "(1064,)\n",
      "akiec\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_cat_acc, test_top_2_acc, test_top_3_acc = model_ret.evaluate_generator(test_generator, steps=test_generator.samples)\n",
    "\n",
    "print('val_loss:', test_loss)\n",
    "print('val_cat_acc:', test_cat_acc)\n",
    "print('val_top_2_acc:', test_top_2_acc)\n",
    "print('val_top_3_acc:', test_top_3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064, 7)\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "predictions = model_ret.predict_generator(test_generator, steps=test_generator.samples, verbose=1)\n",
    "print(predictions.shape)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_test = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064/1064 [==============================] - 31s 29ms/step\n",
      "(1064, 7)\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, target_names=[k.key for k in test_generator.class_indices])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "im_paths = list(paths.list_images(\"ham_labled/test\"))\n",
    "class_names = [imp.split(os.path.sep)[-2] for imp in im_paths]\n",
    "class_names = [str(x) for x in np.unique(class_names)]\n",
    "\n",
    "report = classification_report(\n",
    "    y_test.argmax(axis=1),\n",
    "    y_pred.argmax(axis=1),\n",
    "    target_names=class_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      akiec       0.00      0.00      0.00        66\n",
      "        bcc       0.00      0.00      0.00       103\n",
      "        bkl       0.00      0.00      0.00       220\n",
      "         df       0.00      0.00      0.00        23\n",
      "        mel       0.50      0.02      0.03       223\n",
      "         nv       0.00      0.00      0.00       400\n",
      "       vasc       0.03      1.00      0.05        29\n",
      "\n",
      "avg / total       0.11      0.03      0.01      1064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the loss\n",
    "plt.plot(history.history_ret['loss'])\n",
    "plt.plot(history.history_ret['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
