{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "      <td>9958.000000</td>\n",
       "      <td>10015</td>\n",
       "      <td>10015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7470</td>\n",
       "      <td>10015</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>HAM_0005263</td>\n",
       "      <td>ISIC_0032137</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6705</td>\n",
       "      <td>5340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5406</td>\n",
       "      <td>2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.863828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.968614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lesion_id      image_id     dx dx_type          age    sex  \\\n",
       "count         10015         10015  10015   10015  9958.000000  10015   \n",
       "unique         7470         10015      7       4          NaN      3   \n",
       "top     HAM_0005263  ISIC_0032137     nv   histo          NaN   male   \n",
       "freq              6             1   6705    5340          NaN   5406   \n",
       "mean            NaN           NaN    NaN     NaN    51.863828    NaN   \n",
       "std             NaN           NaN    NaN     NaN    16.968614    NaN   \n",
       "min             NaN           NaN    NaN     NaN     0.000000    NaN   \n",
       "25%             NaN           NaN    NaN     NaN    40.000000    NaN   \n",
       "50%             NaN           NaN    NaN     NaN    50.000000    NaN   \n",
       "75%             NaN           NaN    NaN     NaN    65.000000    NaN   \n",
       "max             NaN           NaN    NaN     NaN    85.000000    NaN   \n",
       "\n",
       "       localization  \n",
       "count         10015  \n",
       "unique           15  \n",
       "top            back  \n",
       "freq           2192  \n",
       "mean            NaN  \n",
       "std             NaN  \n",
       "min             NaN  \n",
       "25%             NaN  \n",
       "50%             NaN  \n",
       "75%             NaN  \n",
       "max             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"../HAM10000_metadata.csv\")\n",
    "metadata.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
     ]
    }
   ],
   "source": [
    "print(metadata.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n"
     ]
    }
   ],
   "source": [
    "labels = list(metadata.dx.unique())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: dx, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fed10fc8198>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 5))\n",
    "counts = metadata[\"dx\"].value_counts()\n",
    "print(counts)\n",
    "counts.plot(kind='bar', ax=ax1)\n",
    "#metadata[\"dx\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse out all classes to individual dataframes\n",
    "nv = metadata[metadata[\"dx\"] == \"nv\"]\n",
    "nv.name = \"nv\"\n",
    "mel = metadata[metadata[\"dx\"] == \"mel\"]\n",
    "mel.name = \"mel\"\n",
    "bkl = metadata[metadata[\"dx\"] == \"bkl\"]\n",
    "bkl.name = \"bkl\"\n",
    "bcc = metadata[metadata[\"dx\"] == \"bcc\"]\n",
    "bcc.name = \"bcc\"\n",
    "akiec = metadata[metadata[\"dx\"] == \"akiec\"]\n",
    "akiec.name = \"akiec\"\n",
    "vasc = metadata[metadata[\"dx\"] == \"vasc\"]\n",
    "vasc.name = \"vasc\"\n",
    "df = metadata[metadata[\"dx\"] == \"df\"]\n",
    "df.name = \"df\"\n",
    "# list out\n",
    "classes = [nv, mel, bkl, bcc, akiec, vasc, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess accordingly\n",
    "def preprocess(_image):\n",
    "    #_image = cv2.cvtColor(_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #_image = cv2.equalizeHist(_image) \n",
    "    #_image = cv2.GaussianBlur(_image, (3,3), 1)\n",
    "    _image = cv2.cvtColor(_image, cv2.COLOR_RGB2HSV)\n",
    "    H,S,V = cv2.split(_image)\n",
    "    _V = cv2.equalizeHist(V) \n",
    "    _image = cv2.merge([H, S, _V])\n",
    "    _image = cv2.cvtColor(_image, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return _image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate into Respective Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 5364, Test: 1341 images found for class nv\n",
      "Moving complete for class nv...\n",
      "Training: 890, Test: 223 images found for class mel\n",
      "Moving complete for class mel...\n",
      "Training: 879, Test: 220 images found for class bkl\n",
      "Moving complete for class bkl...\n",
      "Training: 411, Test: 103 images found for class bcc\n",
      "Moving complete for class bcc...\n",
      "Training: 261, Test: 66 images found for class akiec\n",
      "Moving complete for class akiec...\n",
      "Training: 113, Test: 29 images found for class vasc\n",
      "Moving complete for class vasc...\n",
      "Training: 92, Test: 23 images found for class df\n",
      "Moving complete for class df...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seperate images to each directory \n",
    "os.mkdir(\"ham_labled\")\n",
    "os.mkdir(\"ham_labled/train\")\n",
    "os.mkdir(\"ham_labled/test\")\n",
    "\n",
    "# each class\n",
    "for _class in classes:\n",
    "    _train, _test = train_test_split(_class, test_size = 0.2)\n",
    "    print(\"Training: {}, Test: {} images found for class {}\".format(len(_train), len(_test), _class.name))\n",
    "    # train \n",
    "    os.mkdir(\"ham_labled/train/{}\".format(_class.name))\n",
    "    for i, row in _train.iterrows():\n",
    "        image_id = row[\"image_id\"]\n",
    "        img = cv2.imread(\"../ham10000/{}.jpg\".format(image_id))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        cv2.imwrite(\"../ham10000/{}.jpg\".format(image_id), img)\n",
    "        shutil.move(\n",
    "            src=\"../ham10000/{}.jpg\".format(image_id), \n",
    "            dst=\"ham_labled/train/{}/\".format(_class.name)\n",
    "        )\n",
    "    # test\n",
    "    os.mkdir(\"ham_labled/test/{}\".format(_class.name))\n",
    "    for i, row in _test.iterrows():\n",
    "        image_id = row[\"image_id\"]\n",
    "        img = cv2.imread(\"../ham10000/{}.jpg\".format(image_id))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        cv2.imwrite(\"../ham10000/{}.jpg\".format(image_id), img)\n",
    "        shutil.move(\n",
    "            src=\"../ham10000/{}.jpg\".format(image_id), \n",
    "            dst=\"ham_labled/test/{}/\".format(_class.name)\n",
    "        )\n",
    "    print(\"Moving complete for class {}...\".format(_class.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augumentation\n",
    "\n",
    "Before we can start passing above images through a CNN feature extractor, we will augument images to address class imbalance problem and set a threshold of 5000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "_generator = ImageDataGenerator(\n",
    "    width_shift_range=0.001,\n",
    "    height_shift_range=0.001,\n",
    "    zoom_range=0.01,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "def load_images(directory):\n",
    "    images = [cv2.cvtColor(cv2.imread(os.path.join(directory, file)), cv2.COLOR_BGR2RGB)\n",
    "              for file in os.listdir(directory)]\n",
    "    images = [img_to_array(image, data_format=\"channels_last\") for image in images]\n",
    "    images = np.array(images)\n",
    "    images = images.astype(\"float\")\n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augumenting images for class mel...\n",
      "Augumenting images for class bkl...\n",
      "Augumenting images for class bcc...\n",
      "Augumenting images for class akiec...\n",
      "Augumenting images for class vasc...\n",
      "Augumenting images for class df...\n"
     ]
    }
   ],
   "source": [
    "threshold = 3000\n",
    "batch = 32\n",
    "for _class in classes:\n",
    "    _name = _class.name\n",
    "    if len(_class) >= threshold:\n",
    "        continue\n",
    "    else:\n",
    "        # what a pain ....PHEW!\n",
    "        if os.path.exists(\"ham_labled/train/{}/.ipynb_checkpoints/\".format(_name)):\n",
    "            shutil.rmtree(\"ham_labled/train/{}/.ipynb_checkpoints/\".format(_name))\n",
    "        print(\"Augumenting images for class {}...\".format(_name))\n",
    "        X = load_images(\"ham_labled/train/{}/\".format(_name))\n",
    "        _auguments = _generator.flow(\n",
    "            x=X,\n",
    "            y=None,\n",
    "            batch_size=batch,\n",
    "            save_format=\"jpg\",\n",
    "            save_prefix=\"augumented\",\n",
    "            save_to_dir=\"ham_labled/train/{}/\".format(_name)\n",
    "        )\n",
    "        for _ in range(int(np.ceil((threshold - X.shape[0])/batch))):\n",
    "            x = next(_auguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the newly generated Images and process them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21673 total images found...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imutils import paths\n",
    "except ModuleNotFoundError:\n",
    "    !pip install imutils\n",
    "    from imutils import paths\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "image_paths = list(paths.list_images(\"ham_labled/train\"))\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "labels = [cls.split(os.path.sep)[-2] for cls in image_paths]\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "print(\"{} total images found...\".format(len(image_paths)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(object):\n",
    "\n",
    "    def __init__(self, height, width, channels, classes, parameter_scaling):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.output_classes = classes\n",
    "        self.scale = parameter_scaling\n",
    "\n",
    "    def model(self):\n",
    "        # initiate model\n",
    "        _model = Sequential()\n",
    "        input_shape = (self.height, self.width, self.channels)\n",
    "        axis = -1\n",
    "        # if using theano\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            input_shape = (self.channels, self.height, self.width)\n",
    "            axis = 1\n",
    "\n",
    "        # conv_1\n",
    "        _model.add(Conv2D(\n",
    "            self.scale, (3, 3),\n",
    "            padding=\"same\",\n",
    "            input_shape=input_shape)\n",
    "        )\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # conv_2\n",
    "        _model.add(Conv2D(self.scale, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # pool_1\n",
    "        _model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        _model.add(Dropout(0.25))\n",
    "\n",
    "        # conv_3\n",
    "        _model.add(Conv2D(self.scale*2, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # conv_4\n",
    "        _model.add(Conv2D(self.scale*2, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # pool_2\n",
    "        _model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        _model.add(Dropout(0.25))\n",
    "        \n",
    "        # conv_5\n",
    "        _model.add(Conv2D(self.scale*3, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # conv_6\n",
    "        _model.add(Conv2D(self.scale*3, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # conv_7\n",
    "        _model.add(Conv2D(self.scale*3, (3, 3), padding=\"same\"))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization(axis=axis))\n",
    "        # pool_3\n",
    "        _model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        _model.add(Dropout(0.25))\n",
    "\n",
    "        # Fully connected layers\n",
    "        _model.add(Flatten())\n",
    "        _model.add(Dense(512))\n",
    "        _model.add(Activation(\"relu\"))\n",
    "        _model.add(BatchNormalization())\n",
    "        _model.add(Dropout(0.5))\n",
    "        # classifier\n",
    "        _model.add(Dense(self.output_classes))\n",
    "        _model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return model\n",
    "        return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17341 images belonging to 7 classes.\n",
      "Found 4332 images belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "246/541 [============>.................] - ETA: 4:18 - loss: 1.6408 - acc: 0.4672"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'PngImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f0a59eb38012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mmodel_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-f0a59eb38012>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    225\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                            interpolation=self.interpolation)\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# but not PIL images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# or (channel, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'PngImageFile'"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "manager = multiprocessing.Manager()\n",
    "queue = manager.Queue(maxsize=10)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 50\n",
    "PARAMETER_SCALING = 64\n",
    "IM_WIDTH = 224\n",
    "IM_HEIGHT = 224\n",
    "\n",
    "def train():\n",
    "    \n",
    "        h_callbacks = [\n",
    "            callbacks.TensorBoard(\n",
    "                log_dir=\"tensorboard\",\n",
    "                write_graph=True,\n",
    "                write_images=False\n",
    "            )\n",
    "        ]\n",
    "        _model = CustomNet(\n",
    "            height=IM_HEIGHT,\n",
    "            width=IM_WIDTH,\n",
    "            channels=3,\n",
    "            classes=7,\n",
    "            parameter_scaling=PARAMETER_SCALING\n",
    "        ).model()\n",
    "        _model.compile(\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            optimizer=Adam(lr=LR),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        # generators made according to the post\n",
    "        # https://github.com/keras-team/keras/issues/5862\n",
    "        data_generator = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        train_generator = data_generator.flow_from_directory(\n",
    "            directory=\"ham_labled/train\",\n",
    "            target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset=\"training\"\n",
    "        )\n",
    "        valid_generator = data_generator.flow_from_directory(\n",
    "            directory=\"ham_labled/train\",\n",
    "            target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"categorical\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            subset=\"validation\"\n",
    "        )\n",
    "        # train\n",
    "        history = _model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "            validation_data=valid_generator,\n",
    "            validation_steps=valid_generator.n//valid_generator.batch_size,\n",
    "            callbacks=h_callbacks,\n",
    "            epochs=EPOCHS\n",
    "        )\n",
    "        return _model, history\n",
    "\n",
    "model_ret, history_ret = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th image of 21673\n",
      "0\n",
      "ham_labled/train/bkl/augumented_668_3668.png\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i,im in enumerate(image_paths):\n",
    "    if i%1000 == 0:\n",
    "        print(\"{} th image of {}\".format(i, len(image_paths)))\n",
    "    try:\n",
    "        img = Image.opeb(im)\n",
    "    except:\n",
    "        print(i)\n",
    "        print(im)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mat is not a numpy array, neither a scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b21d46e644f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ImageWindow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ham_labled/train/bkl/augumented_668_3668.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mat is not a numpy array, neither a scalar"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"ImageWindow\", \"ham_labled/train/bkl/augumented_668_3668.png\")\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and CNN Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class HDF5IO has the utilities to read/write extracted features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "class HDF5IO:\n",
    "\n",
    "    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n",
    "        if os.path.exists(output_path):\n",
    "            raise ValueError(\n",
    "                \"The path already exists and cannot be overwritten\",\n",
    "                output_path\n",
    "            )\n",
    "        self.db = h5py.File(output_path, \"w\")\n",
    "        self.data = self.db.create_dataset(\n",
    "            data_key,\n",
    "            dims,\n",
    "            dtype=\"float\"\n",
    "        )\n",
    "        self.labels = self.db.create_dataset(\n",
    "            \"labels\",\n",
    "            (dims[0],),\n",
    "            dtype=\"int\"\n",
    "        )\n",
    "        self.buf_size = buf_size\n",
    "        self.buffer = {\"data\": [], \"labels\": []}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add(self, rows, labels):\n",
    "        \"\"\"\n",
    "        Adds the rows and labels to the buffer\n",
    "        :param rows:\n",
    "        :param labels:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.buffer[\"data\"].extend(rows)\n",
    "        self.buffer[\"labels\"].extend(labels)\n",
    "        # check to see if the buffer needs to be flushed to disk\n",
    "        if len(self.buffer[\"data\"]) >= self.buf_size:\n",
    "            self.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"\n",
    "        Write the buffers to disk then reset the buffer\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        i = self.idx + len(self.buffer[\"data\"])\n",
    "        self.data[self.idx:i] = self.buffer[\"data\"]\n",
    "        self.labels[self.idx:i] = self.buffer[\"labels\"]\n",
    "        self.idx = i\n",
    "        self.buffer = {\"data\": [], \"labels\": []}\n",
    "\n",
    "    def store_class_labels(self, class_labels):\n",
    "        \"\"\"\n",
    "        create a dataset to store the actual class label names,\n",
    "        then store the class labels\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        dt = h5py.special_dtype(vlen=str)\n",
    "        label_set = self.db.create_dataset(\n",
    "            \"label_names\",\n",
    "            (len(class_labels),),\n",
    "            dtype=dt\n",
    "        )\n",
    "        label_set[:] = class_labels\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Closes the dataset\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if len(self.buffer[\"data\"]) > 0:\n",
    "            self.flush()\n",
    "        # close the dataset\n",
    "        self.db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "# load the VGG16 model with imagenet weights\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HDF5IO(\n",
    "    (len(image_paths), 512 * 7 * 7),\n",
    "    os.path.join(os.getcwd(), \"hmnist_features\"),\n",
    "    data_key=\"features\",\n",
    "    buf_size=1000\n",
    ")\n",
    "dataset.store_class_labels(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:57:51\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "# initialize the progress bar\n",
    "widgets = [\n",
    "    \"Extracting Features: \", progressbar.Percentage(), \" \",\n",
    "    progressbar.Bar(), \" \", progressbar.ETA()\n",
    "]\n",
    "pbar = progressbar.ProgressBar(\n",
    "    maxval=len(image_paths),\n",
    "    widgets=widgets\n",
    ").start()\n",
    "\n",
    "bs = 32\n",
    "\n",
    "# loop over the images in patches\n",
    "for i in np.arange(0, len(image_paths), bs):\n",
    "    # extract the batch of images and labels, then initialize the\n",
    "    # list of actual images that will be passed through the network\n",
    "    # for feature extraction\n",
    "    batch_paths = image_paths[i:i + bs]\n",
    "    batch_labels = labels[i:i + bs]\n",
    "    batch_images = []\n",
    "\n",
    "    # loop over the images and labels in the current batch\n",
    "    for (j, image_path) in enumerate(batch_paths):\n",
    "        \n",
    "        image = load_img(image_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "        # add the image to the batch\n",
    "        batch_images.append(image)\n",
    "\n",
    "    batch_images = np.vstack(batch_images)\n",
    "    features = model.predict(batch_images, batch_size=bs)\n",
    "\n",
    "    features = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "\n",
    "    # add the features and labels to our HDF5 dataset\n",
    "    dataset.add(features, batch_labels)\n",
    "    pbar.update(i)\n",
    "\n",
    "# close the dataset\n",
    "dataset.close()\n",
    "pbar.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading features from disk and applying a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features from disk\n",
    "db = h5py.File(\"hmnist_features\", \"r\")\n",
    "\n",
    "# trian test split\n",
    "i = int(db[\"labels\"].shape[0] * 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 15.8min finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(\n",
    "    solver=\"lbfgs\", \n",
    "    multi_class=\"auto\",\n",
    "    n_jobs=-1,\n",
    "    C=10.0,\n",
    "    verbose=10.0\n",
    ")\n",
    "model.fit(db[\"features\"][:i], db[\"labels\"][:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.00      0.00      0.00         0\n",
      "         bcc       0.87      0.92      0.89      2044\n",
      "         bkl       0.00      0.00      0.00         0\n",
      "          df       0.00      0.00      0.00         0\n",
      "         mel       0.00      0.00      0.00      5027\n",
      "          nv       0.00      0.00      0.00         0\n",
      "        vasc       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.27      0.27      0.27      7071\n",
      "   macro avg       0.12      0.13      0.13      7071\n",
      "weighted avg       0.25      0.27      0.26      7071\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cn180450/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/cn180450/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(db[\"features\"][i:])\n",
    "print(\n",
    "    classification_report(\n",
    "        db[\"labels\"][i:], \n",
    "        preds,\n",
    "        target_names=db[\"label_names\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
